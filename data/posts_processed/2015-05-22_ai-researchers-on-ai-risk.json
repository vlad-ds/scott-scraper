{
    "title": "AI Researchers On AI Risk",
    "date": "May 22, 2015",
    "links": [
        "http://www.cnet.com/news/bill-gates-is-worried-about-artificial-intelligence-too/",
        "http://www.bbc.com/news/technology-30290540",
        "http://www.forbes.com/sites/ericmack/2015/01/15/elon-musk-puts-down-10-million-to-fight-skynet/",
        "http://www.popsci.com/bill-gates-fears-ai-ai-researchers-know-better",
        "http://fusion.net/story/54583/the-case-against-killer-robots-from-a-guy-actually-building-ai/",
        "http://marginalrevolution.com/marginalrevolution/2015/05/what-do-ai-researchers-think-of-the-risks-of-ai.html",
        "http://en.wikipedia.org/wiki/Stuart_J._Russell",
        "http://www.amazon.com/gp/product/0136042597/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0136042597&linkCode=as2&tag=slastacod-20&linkId=KI5CQ6KYVQTMTRB6",
        "https://www.cs.berkeley.edu/~russell/research/future/",
        "http://edge.org/response-detail/26157",
        "https://intelligence.org/2014/05/13/christof-koch-stuart-russell-machine-superintelligence/",
        "http://en.wikipedia.org/wiki/David_A._McAllester",
        "http://technews.acm.org/archives.cfm?fo=2009-11-nov/nov-06-2009.html",
        "https://machinethoughts.wordpress.com/2014/08/10/friendly-ai-and-the-servant-mission/",
        "http://blog.computationalcomplexity.org/2009/07/singularity.html",
        "http://en.wikipedia.org/wiki/Hans_Moravec",
        "http://en.wikipedia.org/wiki/Moravec%27s_paradox",
        "http://seegrid.com/product/vision-guided-vehicles/",
        "http://www.aaai.org/ojs/index.php/aimagazine/article/viewArticle/676",
        "http://www.amazon.com/gp/product/0195136306/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0195136306&linkCode=as2&tag=slastacod-20&linkId=YSNWMXT4POFD425Q",
        "http://en.wikipedia.org/wiki/Google_DeepMind",
        "http://www.vetta.org/documents/Machine_Super_Intelligence.pdf",
        "http://future.wikia.com/wiki/Scenario:_Shane_Legg",
        "http://en.wikipedia.org/wiki/Demis_Hassabis",
        "http://en.wikipedia.org/wiki/Mustafa_Suleyman",
        "http://www.forbes.com/sites/privacynotice/2014/02/03/inside-googles-mysterious-ethics-board/",
        "en.wikipedia.org/wiki/Steve_Omohundro",
        "http://selfawaresystems.com/",
        "https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf",
        "http://steveomohundro.com/scientific-contributions/",
        "http://www.doc.ic.ac.uk/~mpsha/",
        "http://www.amazon.com/gp/product/0262527804/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0262527804&linkCode=as2&tag=slastacod-20&linkId=7NK3HKZJTIAT2WU5",
        "http://en.wikipedia.org/wiki/Marcus_Hutter",
        "http://www.hutter1.net/publ/singularity.pdf",
        "http://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber",
        "https://books.google.com/books?id=gVxGAAAAQBAJ&pg=PA8&lpg=PA8&dq=%22juergen+schmidhuber%22+singularity&source=bl&ots=vpfD_69J8B&sig=HOhUv_JABWg0kXpsMfuCcX7zB8I&hl=en&sa=X&ei=801dVY6LK5CQoQSCoIOoAQ&ved=0CCQQ6AEwATgK#v=onepage&q=%22juergen%20schmidhuber%22%20singularity&f=false",
        "https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp65ico",
        "http://people.idsia.ch/~juergen/2012futurists.pdf",
        "http://en.wikipedia.org/wiki/Richard_S._Sutton",
        "http://www.amazon.com/gp/product/0262193981/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0262193981&linkCode=as2&tag=slastacod-20&linkId=HCZ4TIUPMZNBFWEC",
        "http://futureoflife.org/misc/ai_conference",
        "http://www.vetta.org/2011/05/sutton-on-human-level-ai/",
        "https://books.google.com/books?id=_4Es5GmiNJEC&pg=PA264&lpg=PA264&dq=%22Richard+Sutton%22+%22Glenn+Beck%22&source=bl&ots=TVvjBwnQX1&sig=awXV752hsO6VfbAlC0srVRqTcQs&hl=en&sa=X&ei=JZNdVfKeFIKuogTVo4DwDA&ved=0CCsQ6AEwAg#v=onepage&q=%22Richard%20Sutton%22%20%22Glenn%20Beck%22&f=false",
        "http://www.doc.ic.ac.uk/~ajd/",
        "http://www.doc.ic.ac.uk/~ajd/singularity.html",
        "http://en.wikipedia.org/wiki/Alan_Turing",
        "http://en.wikipedia.org/wiki/I._J._Good",
        "http://webdocs.cs.ualberta.ca/~sutton/Good65ultraintelligent.pdf",
        "http://www.nickbostrom.com/papers/survey.pdf",
        "http://lesswrong.com/lw/e79/ai_timeline_prediction_data/",
        "http://www.amazon.com/gp/product/B00IB4N4KU/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00IB4N4KU&linkCode=as2&tag=slastacod-20&linkId=L3KTZD5JGHSRYCSQ",
        "http://www.popsci.com/bill-gates-fears-ai-ai-researchers-know-better",
        "http://marginalrevolution.com/marginalrevolution/2015/05/what-do-ai-researchers-think-of-the-risks-of-ai.html",
        "http://www.kdnuggets.com/2014/02/exclusive-yann-lecun-deep-learning-facebook-ai-lab-part2.html",
        "http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/facebook-ai-director-yann-lecun-on-deep-learning#qaTopicEight",
        "http://www.bbc.com/news/technology-31023741",
        "http://www.stuff.co.nz/technology/digital-living/65551109/Nothing-to-fear-from-artificial-intelligence-Microsofts-Eric-Horvitz",
        "http://www.slate.com/articles/technology/future_tense/2014/10/elon_musk_artificial_intelligence_why_you_shouldn_t_be_afraid_of_ai.html",
        "https://medium.com/backchannel/ai-wont-exterminate-us-it-will-empower-us-5b7224735bf3",
        "http://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0199678111&linkCode=as2&tag=slastacod-20&linkId=KXW3Z5OQNRXKMZNC",
        "https://intelligence.org/",
        "http://futureoflife.org/"
    ],
    "url": "https://slatestarcodex.com/2015/05/22/ai-researchers-on-ai-risk/",
    "summary": "Key ideas:\n- Most people used to think AI risk was a topic for \"random Internet crackpots\" until influential figures like Bill Gates and Elon Musk publically announced their concerns about it.\n- Some articles cherry-pick AI researchers who are not worried about superintelligence and ignore those who are.\n- The author lists prestigious AI and machine learning researchers who have publicly expressed concern about AI risks and superintelligence.\n- \"Controversy\" assumes there are dueling opinions, but there is a widespread agreement among the most respected researchers that control and safety issues will become central to AI as the field matures.\n- The possibility of an intelligence explosion resulting from the development of superintelligent AI machines.\n- The advancement of the technology might lead to the development of a society of these maximally intelligent individuals.\n- G\u00f6del machine is one of the artificial intelligence techniques that could offer a way of shaping future superintelligences.\n- AI researchers expect a 50% chance of human-level AI by 2040 and 90% chance of human-level AI by 2075.\n- There are some reasons to worry about sampling bias.\n- The difference between skeptics and believers isn\u2019t about when human-level AI will arrive, it\u2019s about when we should start preparing.\n- The structure of your work can keep you on track.\n- Sticking to a pre-defined structure leads to better work than free-form writing.\n- Minsky's model of the mind explains how we need structure to learn and work effectively.\n\nKey learnings:\n- Many influential figures and experts in the field of AI and machine learning have expressed concern about AI risk and superintelligence.\n- AI researchers who express concern are focusing on strategies and measures to improve control and safety in AI, similar to how nuclear fusion researchers focus on containing fusion reactions as a primary issue in their field.\n- AI researchers expect human-level AI to arrive between 2040 - 2075.\n- Scientists and the general public should talk about the technological singularity.\n- G\u00f6del machine could shape the future of superintelligences.\n- Sampling bias could be problematic.\n- The disagreement among AI researchers is about when we should start preparing for AI research, rather than when human-level AI will arrive.\n- Following a structure allows for more focused and concise writing.\n- Develop a structure beforehand to avoid getting sidetracked.\n- Structure can help develop a stronger memory of the information you are working with.\n\nKey questions:\n- How can we improve the chances of reaping the benefits and avoiding risks of AI technology?\n- What are the potential consequences of superintelligent machines?\n- What are the basic drives of advanced AI systems, and how can we use this knowledge to design utility functions for a positive future for humanity?\n- What precautions should we take in shaping the future of superintelligences?\n- What will be the consequences of human-level AI?\n- How accurate is the survey conducted by AI researchers?\n- What are the risks of AI development?\n- When should we start taking action to prepare for AI research?\n- How can I use Minsky's model of the mind to improve my writing?\n- What is the balance between structure and creativity in writing?\n- How can I develop a structure that works for me and my writing style?\n"
}