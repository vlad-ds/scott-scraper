{
    "title": "In Mod We Trust",
    "date": "February 27, 2019",
    "links": [
        "https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona",
        "https://slatestarcodex.com/2019/02/22/rip-culture-war-thread/",
        "https://www.usatoday.com/story/news/politics/2018/07/17/gop-lawmakers-press-facebook-twitter-anti-conservative-bias/792555002/"
    ],
    "url": "https://slatestarcodex.com/2019/02/27/in-mod-we-trust/",
    "summary": "Key ideas\n- The Facebook moderation industry is exposed to unpleasant and traumatic material, leading to psychological trauma.\n- Moderation is a difficult and complicated process with potential career consequences for mods and rules nitpicked by higher-ups.\n- Scott examines the tension between the need for moderation and the dehumanizing rules needed to make it effective.\n- The article presents a pessimistic view of information spread, where exposure to conspiracy theories leads to belief or suspicion.\n\nKey learnings\n- Moderation of Facebook is a difficult and unpleasant job, dealing with psychological trauma and nitpicked rules.\n- The tension between effective moderation and preserving the humanizing of the workplace is delicate.\n- Exposure to conspiracy theories can lead people to belief or suspicion.\n\nKey questions\n- What is the potential alternative to Facebook's current moderation process?\n- How can companies balance effective moderation with preserving a humane work environment?\n- Why do normal people exposed to conspiracy theories end up believing them or suspecting them?"
}