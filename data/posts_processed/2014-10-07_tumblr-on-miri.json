{
    "title": "Tumblr on MIRI",
    "date": "October 7, 2014",
    "links": [
        "http://intelligence.org/",
        "https://slatestarcodex.com/2014/08/26/if-the-media-reported-on-other-dangers-like-it-does-ai-risk/",
        "http://gruntledandhinged.com/2014/09/14/on-beginners-and-burning-out/",
        "http://intelligenceexplosion.com/",
        "http://lesswrong.com/r/discussion/lw/l2v/open_thread_oct_6_oct_12_2014/",
        "http://su3su2u1.tumblr.com/",
        "http://www.amazon.com/gp/product/1936661659/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1936661659&linkCode=as2&tag=slastacod-20&linkId=COECOF245ZC5CPDR",
        "http://www.amazon.com/gp/product/1939311098/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1939311098&linkCode=as2&tag=slastacod-20&linkId=IMQHSBDPTWFHQJ5Q",
        "http://www.amazon.com/gp/product/0199678111/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0199678111&linkCode=as2&tag=slastacod-20&linkId=3AA4KAD7OILDHLM2",
        "http://intelligence.org/all-publications/",
        "http://johncarlosbaez.wordpress.com/2013/03/31/probability-theory-and-the-undefinability-of-truth/",
        "http://www.vetta.org/about-me/",
        "http://www.vetta.org/2009/08/funding-safe-agi/",
        "http://www.huffingtonpost.com/2014/01/29/google-ai_n_4683343.html",
        "http://intelligence.org/topdonors/",
        "http://somervta.tumblr.com/",
        "http://nothingismere.tumblr.com/",
        "http://en.wikipedia.org/wiki/Stuart_J._Russell",
        "http://www.cs.berkeley.edu/~russell/research/future/",
        "http://intelligence.org/workshops/",
        "en.wikipedia.org/wiki/Gary_Drescher",
        "en.wikipedia.org/wiki/Steve_Omohundro",
        "http://en.wikipedia.org/wiki/Roman_Yampolskiy",
        "http://en.wikipedia.org/wiki/BlackLight_Power",
        "http://lesswrong.com/lw/hq6/xrisk_roll_call/976f",
        "http://lesswrong.com/lw/jl3/on_saving_the_world/",
        "http://intelligence.org/careers/research-fellow/",
        "http://scholar.google.com/scholar?cites=10134633916327307541&as_sdt=80000005&sciodt=0,23&hl=en",
        "http://intelligence.org/2013/04/13/miris-strategy-for-2013/",
        "http://intelligence.org/2014/06/11/mid-2014-strategic-plan/",
        "http://squid314.livejournal.com/330825.html",
        "https://slatestarcodex.com/2014/02/16/nootropics-survey-results-and-analysis/",
        "http://intelligence.org/all-publications/",
        "http://rationalconspiracy.com/2014/10/06/academic-support-for-miri/",
        "http://en.wikipedia.org/wiki/Goodhart%27s_law",
        "http://rationalconspiracy.com/2014/10/06/academic-support-for-miri/",
        "http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/",
        "http://paulfchristiano.com/ai-impacts/",
        "http://intelligence.org/careers/",
        "http://www.fhi.ox.ac.uk/research/publications/",
        "http://www.fhi.ox.ac.uk/support-fhi/",
        "http://www.nickbostrom.com/fable/dragon.html"
    ],
    "url": "https://slatestarcodex.com/2014/10/07/tumblr-on-miri/",
    "summary": "Key ideas:\n- MIRI is a nonprofit organization dedicated to the risks surrounding \"intelligence explosion\".\n- MIRI works to create more stable goal systems that allow AIs to become intelligent or superintelligent while still acting in predictable and human-friendly ways.\n- MIRI has been successful in outreach and networking. It has gotten attention and endorsements from people like Stephen Hawking, Elon Musk, and Peter Thiel.\n- MIRI conducts academic research, has publications, book chapters, and other things associated with normal academic research.\n- MIRI's researchers are not considered to be as prestigious as those at other organizations.\n- MIRI has shifted their focus from outreach and strategic research to pure math research in recent years.\n- MIRI has not published much research due to their previous focus on strategic research and outreach.\n- There is a lack of citations for MIRI's work.\n- MIRI has recruited new researchers and seeks to hire a full-time science writer.\n- The New York rationalist group takes a more combative approach to academia, arguing that it is too focused on publishing papers and citations rather than actual progress.\n- The author agrees with the rationalist group, criticizing the process of official, published research as a \"crappy game.\"\n- One member of the community argues that the direct measure of MIRI's success in outreach is through citations, of which MIRI's is very low.\n- There is disagreement over whether MIRI's success in bringing AI risk to the public eye deserves credit or if they failed to follow up.\n- MIRI has done a poor job getting published and cited results in journals, which is necessary for robust mathematical progress.\n\nKey learnings:\n- MIRI is successful in getting attention, press coverage, and interest from smart people not in the field. This is good fundraising and PR, but it doesn't mean they're good at anything else.\n- MIRI needs more support from smart people in the fields of math, AI, and computer science.\n- MIRI's output may not be as impressive as expected by those familiar with academic culture. It seems to have gotten about five ten solid publications in during its decade-long history as a multi-person organization; one good grad student can get a couple solid publications a year.\n- MIRI has many employees/associates with strong qualifications and published work in math and compsci.\n- MIRI has been unsuccessful in getting academic interest and citations despite their efforts.\n- There is a debate over the best way to measure success and progress in a new field, particularly with regards to AI risk.\n- Building up public interest and garnering media attention is a good first step, but it must be followed up with published papers and citations to achieve real progress.\n- Inexperience and lack of experience in academic writing may be a limiting factor for MIRI and other similar organizations.\n\nKey questions:\n- What is the difference between outreach and self-promotion?\n- Is MIRI successful in outreach if it gets Stephen Hawking to say \"We need to be more concerned about AI risks, as described by organizations like MIRI\"?\n- Does MIRI have enough support from smart people in the fields of math, AI, and computer science?\n- How many brilliant PhDs from top universities should MIRI have given their limited budget?\n- Should MIRI be focusing on publishing more to gain academic interest and citations?\n- Is the lack of published research for MIRI purely due to their emphasis on strategic research and outreach in the past?\n- What is the best way to measure success and progress in a new field such as AI risk?\n- How can small organizations like MIRI balance research and the need for publishing papers and citations?\n- How can those with experience in academic writing or other fields help advance progress in this area?\n"
}