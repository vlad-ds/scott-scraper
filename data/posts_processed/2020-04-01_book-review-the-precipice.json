{
    "title": "Book Review: The Precipice",
    "date": "April 1, 2020",
    "links": [
        "https://www.amazon.com/Precipice-Existential-Risk-Future-Humanity-ebook/dp/B07V9GHKYP/ref=as_li_ss_tl?crid=YN9TIAZ7T8IC&keywords=the+precipice&qid=1585806254&sprefix=the+precipi,aps,212&sr=8-2&&linkCode=ll1&tag=slatestarcode-20&linkId=9ab3f571aa7f94cc9e36adbd9281f86b&language=en_US",
        "http://www.slate.com/blogs/atlas_obscura/2013/10/24/a_terrifying_tour_of_the_world_s_most_dangerous_road_north_yungas_in_bolivia.html",
        "https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/",
        "https://www.lesswrong.com/posts/GrtbTAPfkJa4D6jjH/confidence-levels-inside-and-outside-an-argument",
        "https://www.vox.com/future-perfect/2019/6/13/18660548/climate-change-human-civilization-existential-risk",
        "https://slatestarcodex.com/2020/01/30/book-review-human-compatible/",
        "https://slatestarcodex.com/2019/08/27/book-review-reframing-superintelligence/",
        "https://slatestarcodex.com/2017/06/08/ssc-journal-club-ai-timelines/",
        "https://80000hours.org/",
        "https://en.wikipedia.org/wiki/Cosmological_horizon#Event_horizon",
        "https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/"
    ],
    "url": "https://slatestarcodex.com/2020/04/01/book-review-the-precipice/",
    "summary": "Key ideas:\n- Toby Ord's book, The Precipice, warns of existential risks that could completely destroy humanity or ruin its potential.\n- Ord argues that we should take these risks very seriously and prioritize protecting the long-term future of humanity.\n- The book analyzes specific risks, such as nuclear war and global warming.\n- The book \"The Precipice\" by Toby Ord identifies five risks that could lead to human extinction or failure to realize potential.\n- The risks are from natural catastrophes, environmental disasters, pandemics, AI, and miscellaneous factors such as dystopias or unpreparedness for disasters.\n- Ord believes that most of these risks are unlikely to lead to human extinction but cautions that humanity is significantly underprepared to mitigate them.\n- Different populations should follow different courses of action to mitigate these risks.\n- The Precipice is a book that explores existential risks facing humanity.\n- One of these risks is the possibility of human extinction caused by a natural or human-made disaster.\n- The author, Scott, uses a risk assessment framework to explore this risk.\n- He argues that the risk of human extinction may be higher than people generally believe.\n- The book's main message is that humanity needs to invest in reducing these risks.\n\nKey learnings:\n- The potential future of the human race is vast, with quintillions of humans possibly inhabiting the galaxy.\n- The main source of existential risk comes from technological risks, such as nuclear war and global warming.\n- Empirical-based methods with justified assumptions should be used to estimate these risks.\n- Many of the risks to humanity's future lie in the realm of technology.\n- A lot of these risks are potentially preventable with more investment and action.\n- There is a significant disparity between the underfunded efforts to prevent existential risks and the potential consequences of not doing so.\n- People should concentrate on causes that affect existential risk directly, but ordinary jobs can still help by donating to charities or contributing to efforts that stabilize and strengthen societies.\n- There are many possible ways that human extinction could happen, including pandemics, asteroid impacts, climate change, nuclear war, and artificial intelligence.\n- The likelihood of these events happening is difficult to estimate, but the consequences could be catastrophic.\n- The most effective way to reduce these risks is to invest in research and development of new technologies and policies.\n- It is important to develop an \"existential risk mindset\" that acknowledges the severity of these risks and the need to prioritize them.\n\nKey questions:\n- How can society prioritize protecting the long-term future of humanity over more immediate concerns?\n- How can we better prepare for and prevent existential risks such as nuclear war and global warming?\n- What other technological risks should society be concerned about?\n- What are the specific actions governments and organizations can take to mitigate the risk of human extinction?\n- How can we better prepare for risks that are unlike anything that has happened before?\n- What are the implications of not addressing existential risks?\n- How can we balance the need for action against these risks with other pressing issues that require our attention?\n- How can we effectively communicate the severity of existential risks to the public and policymakers?\n- What ethical considerations are involved in deciding how to allocate resources to reduce these risks?\n- How can we balance the need to reduce existential risks with other pressing global issues, such as poverty and environmental degradation?\n- What role do individuals, governments, and institutions have in reducing existential risks?\n"
}