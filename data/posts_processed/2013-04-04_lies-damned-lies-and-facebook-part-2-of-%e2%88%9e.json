{
    "title": "Lies, Damned Lies, And Facebook (Part 2 of \u221e)",
    "date": "April 4, 2013",
    "links": [
        "https://slatestarcodex.com/2013/04/04/lies-damned-lies-and-facebook-part-1-of-%e2%88%9e/",
        "http://en.wikipedia.org/wiki/Dor_Yeshorim",
        "http://candyekane.blogspot.com/2006/10/disabled-people-unworthy-of-life.html",
        "http://www.christiananswers.net/q-sum/q-life032.html",
        "http://www.rationalskepticism.org/philosophy/why-aren-t-disabled-people-who-can-t-work-euthanised-t28106.html",
        "https://www.google.com/#q=disabled+people+should+be+killed&hl=en&ei=mzRdUaGMKIT0qQHrxYEg&start=0&sa=N&bav=on.2,or.r_cp.r_qf.&bvm=bv.44770516,d.b2I&fp=bf2f38cb1dba5df8&biw=1366&bih=640"
    ],
    "url": "https://slatestarcodex.com/2013/04/04/lies-damned-lies-and-facebook-part-2-of-%e2%88%9e/",
    "summary": "Key ideas:\n- Disability rights advocates are unfairly accused of strawmanning complex issues\n- A Facebook meme claimed that Google auto-complete suggested that \"disabled people should be killed\"\n- The author investigated the claim and found it to be misleading\n- Google's auto-complete suggests violent or extreme statements for many demographic groups\n\nKey learnings:\n- Claims that seem too outrageous to be true should be investigated before reacting strongly\n- Auto-complete suggestions are based on popular search queries and may not reflect reality\n- Search algorithms can be biased and produce troubling results\n\nKey questions:\n- Should we hold corporations responsible for the behavior of their algorithms?\n- How can we design search algorithms to produce more accurate and reliable results?\n- How can we combat the spread of false or misleading information on social media?"
}