{
    "title": "Meaningful",
    "date": "February 28, 2019",
    "links": [
        "https://slatestarcodex.com/2019/02/18/do-neural-nets-dream-of-electric-hobbits/"
    ],
    "url": "https://slatestarcodex.com/2019/02/28/meaningful/",
    "summary": "Key ideas:\n- An AI can understand relationships between words, but not necessarily have a concept of reality.\n- Humans also understand relationships between things and make predictions, but may not necessarily understand the underlying reality.\n- There may be deeper levels of understanding humans are incapable of accessing.\n\nKey learnings:\n- Our understanding is based on relationships between things, not necessarily on a direct understanding of reality.\n- Even if we only have a statistical or abstract understanding, it is still impressive that we can get that far.\n\nKey questions:\n- How can we distinguish between a statistical or abstract understanding and an understanding of reality?\n- Are there really deeper levels of understanding that humans are incapable of accessing?"
}